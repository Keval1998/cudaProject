{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HistoEqualize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Keval1998/cudaProject/blob/master/HistoEqualize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Drn184fahA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "5f967333-1d1d-4233-d4c0-dc6331425884"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSOGoSjMfmEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "9314fb2d-0468-41ce-f277-156e0f6371a7"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-xqcrxk8s\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-xqcrxk8s\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=002ba8bcd936df9b8c24c8df17f86b9236a48d458925d43e92d5f10e0aa36759\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u9qk9d4j/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK2sbjiAg-_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "54c7dc15-c5c7-42de-febe-0b8e2c6bfaf0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIs-ieCDfyO9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4c4c58c3-5a6f-44f0-a293-d8a6d38df9ff"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxcbdGd2f8--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "61c63d4d-5750-4f0b-d117-adecfedea863"
      },
      "source": [
        "%%cu\n",
        "#include<cstdlib>\n",
        "#include<iostream>\n",
        "using namespace std;\n",
        "#include<cuda.h>\n",
        "#include<stdio.h>\n",
        "\n",
        "__global__ void histogramKernel(int *data,int *bins,long long int N, int N_bins)\n",
        "{\n",
        "\tint tid = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\tif(tid<N)\n",
        "\t{\n",
        "\t\tatomicAdd(&bins[data[tid]],1);\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void histogramKernelShared(int *data,int *bins,long long int N, int N_bins, float *binsnew)\n",
        "{\n",
        "\textern __shared__ int s_bins[];\n",
        "\tint tid = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\tif(threadIdx.x < N_bins)s_bins[threadIdx.x]=0;\n",
        "\t__syncthreads();\n",
        "\tif(tid<N)\n",
        "\t{\n",
        "\t\tatomicAdd(&s_bins[data[tid]],1);\n",
        "\t__syncthreads();\n",
        "\t\tif(threadIdx.x < N_bins)\n",
        "\t{\n",
        "\t\t\tatomicAdd(&bins[threadIdx.x],s_bins[threadIdx.x]);\n",
        "\t\t__syncthreads();\n",
        "\t\t__shared__ float s_binsnew[256];\n",
        "        s_binsnew[threadIdx.x]=0.00;\n",
        "       for(int i=0;i<=threadIdx.x;i++) s_binsnew[threadIdx.x]+=bins[i];\n",
        "      __syncthreads();\n",
        "       s_binsnew[threadIdx.x]=round((s_binsnew[threadIdx.x]/N)*N_bins-1);\n",
        "\t\t\t__syncthreads();\n",
        "       if (s_binsnew[threadIdx.x]>N_bins-1)s_binsnew[threadIdx.x]=N_bins-1;\n",
        "      __syncthreads();\n",
        "\t\tbinsnew[threadIdx.x] = s_binsnew[threadIdx.x];\n",
        "\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void mapHistogram(int *data,long long int N,float *binsnew)\n",
        "{\n",
        "\tint tid = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\tif(tid<N)data[tid]=binsnew[data[tid]];\n",
        "}\n",
        "\n",
        "void init_array(int *a, int N)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=0;\n",
        "}\n",
        "\n",
        "void init_arrayf(float *a, int N)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=0;\n",
        "}\n",
        "\n",
        "void init_long_array(int *a,long long int N,int N_bins)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=rand()%N_bins;\n",
        "}\n",
        "\n",
        "void histogram(int *arr, int *bins, long long int N)\n",
        "{\n",
        "\tfor (long long int i=0;i<N;i++)\n",
        "\t{\n",
        "\t\tbins[arr[i]]++;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void print_arr(int *arr, int N)\n",
        "{\n",
        "\tfor (int i=0;i<N;i++)\n",
        "\t{\n",
        "\t\t//if(arr[i]!=0)\n",
        "\t\t\tcout<<i<<\"->\"<<arr[i]<<endl;\n",
        "\t}\n",
        "\tcout<<endl;\n",
        "}\n",
        "\n",
        "void print_arrf(float *arr, int N)\n",
        "{\n",
        "\tfor (int i=0;i<N;i++)\n",
        "\t{\n",
        "\t\tcout<<i<<\"->\"<<arr[i]<<endl;\n",
        "\t}\n",
        "\tcout<<endl;\n",
        "}\n",
        "\n",
        "\n",
        "void print_long_arr(int *arr,long long int N)\n",
        "{\n",
        "\tfor (int i=0;i<N;i++)\n",
        "\t{\n",
        "\t\tcout<<arr[i]<<\" \";\n",
        "\t}\n",
        "\tcout<<endl;\n",
        "}\n",
        "\n",
        "void printSum(int *arr,int N)\n",
        "{\n",
        "\tlong long int sum=0;\n",
        "\tfor(int i=0;i<N;i++)sum+=arr[i];\n",
        "\tcout<<\"Verification of total is: \" << sum<<endl;\n",
        "}\n",
        "\n",
        "void printSumf(float *arr,int N)\n",
        "{\n",
        "\tfloat sum=0.0;\n",
        "\tfor(int i=0;i<N;i++)sum+=arr[i];\n",
        "\tcout<<\"Verification of total is: \" << sum<<endl;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\tint T=1024,B=1;\n",
        "\tint *Data,N_bins,*bins;\n",
        "\tlong long int N = 62500;\n",
        "\n",
        "\tData = (int *)malloc(62500*sizeof(int));\n",
        "\tB = (N+T-1)/T;\n",
        "\t\n",
        "\n",
        "\tN=0;\n",
        "\tFILE *imgvector = fopen(\"dat1.txt\",\"r\");\n",
        "\t\t\n",
        "\twhile (fscanf(imgvector,\"%d\",&Data[N])!=EOF)\n",
        "\t{\n",
        "\t\t\tN++;\n",
        "\t}\n",
        "\tfclose(imgvector);\n",
        "\tfor(N_bins=256;N_bins<257;N_bins*=2)\n",
        "\t{\n",
        "\t\tbins = (int *)malloc(N_bins*sizeof(int));\n",
        "\tcudaEvent_t ss,se;\n",
        "\tfloat st,st2,st3;\n",
        "\n",
        "\t\tinit_array(bins,N_bins);\n",
        "\t\tint *dev_Data2,*dev_bins2;\n",
        "\t\tfloat *dev_bins22,*bins2;\n",
        "\t\tbins2 = (float *)malloc(N_bins*sizeof(float));\n",
        "\n",
        "\t\tinit_arrayf(bins2,N_bins);\n",
        "\t\tcudaMalloc((void**)&dev_Data2,N*sizeof(int));\n",
        "\t\tcudaMalloc((void**)&dev_bins2,N_bins*sizeof(int));\n",
        "\t\tcudaMalloc((void**)&dev_bins22,N_bins*sizeof(float));\n",
        "\n",
        "\t\tcudaMemcpy(dev_Data2, Data , N*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\t\tcudaMemcpy(dev_bins2, bins , N_bins*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\t\tcudaMemcpy(dev_bins22, bins2 , N_bins*sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "\t\tcudaEventCreate(&ss); \n",
        "\t\t\t\t\tcudaEventCreate(&se);\n",
        "\t\t\t\t\tcudaEventRecord(ss);\n",
        "\t\t\t\t\tcudaDeviceSynchronize();\n",
        "\t\t\n",
        "\t\t\t\t\t\thistogramKernelShared<<<B,T,N_bins*sizeof(int)>>>(dev_Data2,dev_bins2,N,N_bins,dev_bins22);\n",
        "\t\t\t\t\t\tmapHistogram<<<B,T>>>(dev_Data2,N,dev_bins22);\n",
        "\n",
        "\t\t\t\t\tcudaEventRecord(se);\n",
        "\t\t\t\t\tcudaEventSynchronize(se);\n",
        "\t\t\t\t\tcudaEventElapsedTime(&st3, ss, se);\n",
        "\t\t\n",
        "\t\tcout<<\"time for execution is:  \"<<st3<<\"ms\";\n",
        "\t\t\n",
        "\t\tcudaMemcpy(bins,dev_bins2,N_bins*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\t\tcudaMemcpy(bins2,dev_bins22,N_bins*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\t\tcudaMemcpy(Data,dev_Data2,N*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\t\n",
        "\t\t//print_arr(bins,N_bins);\n",
        "\t\t//print_arrf(bins2,N_bins);\n",
        "\t\t//printSumf(bins2,N_bins);\n",
        "\t\t\n",
        "\t\t//cout<<endl<<\"New Vector:\"<<endl;\n",
        "\t\t//print_long_arr(Data,N);\n",
        "\n",
        "\t\tint i = 0;\n",
        "\t\tFILE *eqvector = fopen(\"dat2.txt\",\"w\");\n",
        "\t\twhile(i<62500)\n",
        "\t\t\t{\t\tfprintf(eqvector,\"%d\\n\",Data[i]); i+=1; }\n",
        "\t\tfclose(eqvector);\n",
        "\t\n",
        "\t\tcudaFree(dev_Data2);cudaFree(dev_bins2);cudaFree(dev_bins22);\n",
        "\t\tfree(bins2);\n",
        "\t}\n",
        "\tfree(Data);free(bins);\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N is 62500\n",
            "time for execution is:  0.29712ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAnzkFRfEN82",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "355a6085-30fc-4367-a74a-895d86fca5a1"
      },
      "source": [
        "%%cu\n",
        "#include<cstdlib>\n",
        "#include<iostream>\n",
        "using namespace std;\n",
        "#include<cuda.h>\n",
        "#include<stdio.h>\n",
        "\n",
        "void histEq(int *Data, int N, int *bins, int *Data2)\n",
        "{\n",
        "\t\tfloat binsf[256],binsf2[256];\n",
        "\t\tfor(int i=0;i<256;i++){binsf[i]=0;binsf2[i]=0;}\n",
        "\n",
        "\t\tfor(int i=0;i<N;i++)\n",
        "    \tbinsf[Data[i]]+=1.0;\n",
        "\t\tfor (int i=0;i<256;i++)\n",
        "\t\t{\n",
        "\t\tbinsf[i]/=N;\n",
        "\n",
        "\t\t\tfor(int j=0;j<=i;j++)\n",
        "\t\t\tbinsf2[i]+=binsf[j];\n",
        "\t\tbins[i]=(int)round(binsf2[i]*255);\n",
        "\t\t}\n",
        "\t\n",
        "\n",
        "\t\tfor(int i=0;i<N;i++)\n",
        "\t\t\tData2[i]=bins[Data[i]];\n",
        "\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  int N=0;\n",
        "\tFILE *imgvector = fopen(\"dat1.txt\",\"r\");\n",
        "  int *Data,*Data2,*bins;\n",
        "\tbins = (int *)malloc(256*sizeof(int));\n",
        "  Data = (int *)malloc(62500*sizeof(int));\n",
        "  Data2 = (int *)malloc(62500*sizeof(int));\n",
        "\tfor(int i=0;i<256;i++){bins[i]=0;}\n",
        "\n",
        "\twhile (fscanf(imgvector,\"%d\",&Data[N])!=EOF)\n",
        "\t{\n",
        "\t\t\tN++;\n",
        "\t}\n",
        "\tcout<<\"N is \"<<N<<endl;\n",
        "\tfclose(imgvector);\n",
        "\n",
        "\tcout<<endl;\n",
        "\tfor(int i=0;i<N;i++)cout<<Data[i]<<\" \";\n",
        "\tcout<<endl;\n",
        "\t\n",
        "\tcudaEvent_t ss,se;\n",
        "\tfloat st;\n",
        "\tcudaEventCreate(&ss); \n",
        "\t\t\t\tcudaEventCreate(&se);\n",
        "\t\t\t\tcudaEventRecord(ss);\n",
        "\t\t\t\tcudaDeviceSynchronize();\n",
        "\thistEq(Data,N,bins,Data2);\n",
        "\t\t\t\tcudaEventRecord(se);\n",
        "\t\t\t\tcudaEventSynchronize(se);\n",
        "\t\t\t\tcudaEventElapsedTime(&st, ss, se);\n",
        "\t\n",
        "\tcout<<endl<<\"Time for function is: \"<<st<<\"ms\";\n",
        "\tcout<<endl;\n",
        "\t//for(int i=0;i<N;i++)cout<<Data2[i]<<\" \";\n",
        "\n",
        " int i = 0;\n",
        "\t\tFILE *eqvector = fopen(\"dat2.txt\",\"w\");\n",
        "\t\twhile(i<62500)\n",
        "\t\t\t{\t\tfprintf(eqvector,\"%d\\n\",Data2[i]); i+=1; }\n",
        "\t\tfclose(eqvector);\n",
        " free(Data);\n",
        " return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIjgPn68j6Xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "im = Image.open('/content/drive/My Drive/ACproject/1.jpg').convert('L')\n",
        "im_resized = im.resize((250,250), Image.ANTIALIAS)\n",
        "im_resized.save('greyscale.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOtmj4aIj7Sl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "00d4e5b6-011c-4aa5-e893-4d623b79fc44"
      },
      "source": [
        "from matplotlib import pyplot as plt \n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "im=Image.open(\"greyscale.png\")\n",
        "f1=open(\"dat1.txt\",\"w\")\n",
        "pxl=list(im.getdata())\n",
        "\n",
        "for i in pxl:\n",
        "    f1.write(str(i)+\" \")\n",
        "    f1.write(\"\\n\")\n",
        "\n",
        "columnsize,rowsize=im.size\n",
        "\n",
        "a = np.array(pxl)\n",
        "\n",
        "print(a.shape)\n",
        "plt.hist(a, bins = 255)\n",
        "x1,x2,y1,y2 = plt.axis()\n",
        "\n",
        "plt.axis((x1,x2,0,5000))\n",
        "plt.title(\"histogram\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(62500,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAUFElEQVR4nO3dbaxl1X3f8e/PjMERdsODJwjPTD04\nICPSB0JugdTOg+wGxrjqECmlWG2ZWKOOVNmVLaWKh+QFBEcJREqokWorxLgZOw9A7FjQ2C0eg6VU\nSYy5Y2PMQyhDwJoZAzN4gOA6IQX/++Ks6x5uzn2Y+3TmnvX9SFdn77XW2Wets+/89r7r7H0mVYUk\nqQ+vGXcHJElrx9CXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoa91L8mTSf7FiPKfSPLoOPokHa8MfU2s\nqvpfVfXWhdoluTbJ761Fn6RxM/SlVZRkw7j7IA0z9DUpzk/yQJIXktyW5HVJfjrJwZkGST6U5FCS\nF5M8muSdSbYBvwT8myTfSfL11vZNSe5McjTJ/iT/YWg7P5BkT5LnkjyS5Bdnvc6T7bUeAP5Pkg1J\ndid5vL32w0l+dqj9zyf5syQ3Jnk+yV8l+eet/ECSw0l2rMm7qInnWYgmxRXANuBvgT8Dfh74y5nK\nJG8F3g/8s6r6VpKtwAlV9XiSXwPOrqp/N7S9W4EHgTcB5wJ7kzxeVfcA1wBbgbcAJwOfH9Gf9wDv\nBp6tqpeTPA78BPA08K+B30tydlU91dpfBHwcOB34lfb6/x04G/gp4DNJPlNV31nyOyThmb4mx01V\n9a2qOsogLM+fVf8KcBJwXpLXVtWTVfX4qA0l2QK8DfhQVf1tVd3PIJCvak2uAH6tqp6rqoPATXP0\n50BV/Q1AVf1R69/3quo24DHgwqH2T1TVf6uqV4DbgC3AdVX1UlV9Afg7BgcAaVkMfU2Kp4eWvwu8\nfriyqvYDHwSuBQ4nuTXJm+bY1puAo1X14lDZN4FNQ/UHhuqGl0eWJbkqyf1t+uZ54B8Bbxxq8szQ\n8syBYnbZq8YkLYWhr25U1R9U1duBNwMF3DBTNavpt4DTkrxhqOwfAofa8lPA5qG6LaNebmYhyZuB\n32EwvXR6VZ3CYOooSxyKtGSGvrqQ5K1J3pHkJAbz/n8DfK9VPwNsTfIagKo6APw58OvtA+F/AuwE\nZi7rvB24OsmpSTYxCPP5nMzgIHCk9eW9DM70pTVn6KsXJwHXA88ymAr6IeDqVvdH7fHbSb7alt/D\n4MPabwGfBa6pqi+2uuuAg8ATwBeBTwMvzfXCVfUw8JvAXzA4wPxjBh82S2su/icq0vIk+Y/AlVX1\nU+Pui7QQz/SlY5TkzCRvS/KadinoLzD4a0A67i0q9NvNJt9oVx9Mt7LTkuxN8lh7PLWVJ8lN7YaW\nB5JcMLSdHa39Y95sonXsROC3gReBe4A7gI+OtUfSIi1qeifJk8BUVT07VPYbDC5ruz7JbuDUqvpQ\nksuA/wRcxuCGk49U1UVJTgOmgSkGH2rtA36sqp5b6UFJkkZbzvTOdmBPW94DXD5U/ska+DJwSpIz\ngUuBvVV1tAX9XgZ3UEqS1shiv4ahgC8kKeC3q+pm4IyhW8ifBs5oy5t49Y0pB1vZXOWvkmQXsAvg\n5JNP/rFzzz13kV2UJAHs27fv2araOKpusaH/9qo6lOSHGHwHyV8OV1ZVtQPCsrUDys0AU1NTNT09\nvRKblaRuJPnmXHWLmt6pqkPt8TCDqxQuBJ5p0za0x8Ot+SFefYfi5lY2V7kkaY0sGPpJTp65HT3J\nycAlDG4hvxOYuQJnB4MrGGjlV7WreC4GXmjTQHcBl7S7GE9t27lrRUcjSZrXYqZ3zgA+m2Sm/R9U\n1f9Mch9we5KdDL6M6orW/vMMrtzZz+CLr94LUFVHk3wYuK+1u659I6IkaY0c13fkOqcvSccuyb6q\nmhpV5x25ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9\nSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jek\njhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRxYd+klO\nSPK1JH/S1s9Kcm+S/UluS3JiKz+pre9v9VuHtnF1K380yaUrPRhJ0vyO5Uz/A8AjQ+s3ADdW1dnA\nc8DOVr4TeK6V39jakeQ84ErgR4BtwEeTnLC87kuSjsWiQj/JZuDdwMfbeoB3AJ9uTfYAl7fl7W2d\nVv/O1n47cGtVvVRVTwD7gQtXYhCSpMVZ7Jn+fwF+EfheWz8deL6qXm7rB4FNbXkTcACg1b/Q2n+/\nfMRzvi/JriTTSaaPHDlyDEORJC1kwdBP8i+Bw1W1bw36Q1XdXFVTVTW1cePGtXhJSerGhkW0eRvw\nr5JcBrwO+AfAR4BTkmxoZ/ObgUOt/SFgC3AwyQbgB4FvD5XPGH6OJGkNLHimX1VXV9XmqtrK4IPY\ne6rq3wJfAn6uNdsB3NGW72zrtPp7qqpa+ZXt6p6zgHOAr6zYSCRJC1rMmf5cPgTcmuRXga8Bt7Ty\nW4BPJdkPHGVwoKCqHkpyO/Aw8DLwvqp6ZRmvL0k6RhmchB+fpqamanp6etzdkKR1Jcm+qpoaVecd\nuZLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEv\nSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLU\nEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6smDoJ3ldkq8k+XqSh5L8\nSis/K8m9SfYnuS3Jia38pLa+v9VvHdrW1a380SSXrtagJEmjLeZM/yXgHVX1T4HzgW1JLgZuAG6s\nqrOB54Cdrf1O4LlWfmNrR5LzgCuBHwG2AR9NcsJKDkaSNL8FQ78GvtNWX9t+CngH8OlWvge4vC1v\nb+u0+ncmSSu/tapeqqongP3AhSsyCknSoixqTj/JCUnuBw4De4HHgeer6uXW5CCwqS1vAg4AtPoX\ngNOHy0c8Z/i1diWZTjJ95MiRYx+RJGlOiwr9qnqlqs4HNjM4Oz93tTpUVTdX1VRVTW3cuHG1XkaS\nunRMV+9U1fPAl4AfB05JsqFVbQYOteVDwBaAVv+DwLeHy0c8R5K0BhZz9c7GJKe05R8AfgZ4hEH4\n/1xrtgO4oy3f2dZp9fdUVbXyK9vVPWcB5wBfWamBSJIWtmHhJpwJ7GlX2rwGuL2q/iTJw8CtSX4V\n+BpwS2t/C/CpJPuBowyu2KGqHkpyO/Aw8DLwvqp6ZWWHI0maTwYn4cenqampmp6eHnc3JGldSbKv\nqqZG1XlHriR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFD\nX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQl\nqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JEFQz/J\nliRfSvJwkoeSfKCVn5Zkb5LH2uOprTxJbkqyP8kDSS4Y2taO1v6xJDtWb1iSpFEWc6b/MvALVXUe\ncDHwviTnAbuBu6vqHODutg7wLuCc9rML+BgMDhLANcBFwIXANTMHCknS2lgw9Kvqqar6alt+EXgE\n2ARsB/a0ZnuAy9vyduCTNfBl4JQkZwKXAnur6mhVPQfsBbat6GgkSfM6pjn9JFuBHwXuBc6oqqda\n1dPAGW15E3Bg6GkHW9lc5bNfY1eS6STTR44cOZbuSZIWsOjQT/J64DPAB6vqr4frqqqAWokOVdXN\nVTVVVVMbN25ciU1KkppFhX6S1zII/N+vqj9uxc+0aRva4+FWfgjYMvT0za1srnJJ0hpZzNU7AW4B\nHqmq3xqquhOYuQJnB3DHUPlV7Sqei4EX2jTQXcAlSU5tH+Be0sokSWtkwyLavA3498A3ktzfyn4J\nuB64PclO4JvAFa3u88BlwH7gu8B7AarqaJIPA/e1dtdV1dEVGYUkaVEymI4/Pk1NTdX09PS4uyFJ\n60qSfVU1NarOO3IlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQ\nl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J\n6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdWTB0E/y\niSSHkzw4VHZakr1JHmuPp7byJLkpyf4kDyS5YOg5O1r7x5LsWJ3hSJLms5gz/d8Fts0q2w3cXVXn\nAHe3dYB3Aee0n13Ax2BwkACuAS4CLgSumTlQSJLWzoKhX1V/ChydVbwd2NOW9wCXD5V/sga+DJyS\n5EzgUmBvVR2tqueAvfz9A4kkaZUtdU7/jKp6qi0/DZzRljcBB4baHWxlc5X/PUl2JZlOMn3kyJEl\ndk+SNMqyP8itqgJqBfoys72bq2qqqqY2bty4UpuVJLH00H+mTdvQHg+38kPAlqF2m1vZXOWSpDW0\n1NC/E5i5AmcHcMdQ+VXtKp6LgRfaNNBdwCVJTm0f4F7SyiRJa2jDQg2S/CHw08AbkxxkcBXO9cDt\nSXYC3wSuaM0/D1wG7Ae+C7wXoKqOJvkwcF9rd11Vzf5wWJK0yjKYkj8+TU1N1fT09Li7IUnrSpJ9\nVTU1qs47ciWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y\n+pLUEUNfkjpi6EtSRwx9SZrH1t2fG3cXVpShL0kLmKTgN/QlqSOGviQtwtbdn5uIM35DX9KyTUIY\njjKJ4zL0pc4d6xns7PaznzvXtiYxQNcjQ1/S9813ABgV9osJ+PkOEsN1Sz0ozHcAWur2JmUqZxRD\nX92Y5H/Iw8F5LOOcL4znarccs/t5LH0a1W5U/XIOHkt539abVNW4+zCnqampmp6eHnc3NCZbd3+O\nJ69/96LaLdV821/s66+lmT7NjHl4eZSF+r+Y926h11htw2NY6X09+/1c7vaOF0n2VdXUqDrP9LVq\nlvIPafaZ6lLO9Jbymsfap7UKwVHvxbFMZ8z3nPVyVrvc6Z9R25nkv/oW4pm+Vs2xnCmvl3+As8+y\nYeG+j2o3++x11Prs9uvlPerJ8Xq2P9+Z/oa17oz6Mjuo5voTe71YyoeGow5+sw8cs8vX03ui9cUz\nfa2KpZz9SuvNejzTd05fc1rNQO55TlWTZb39Lhv6krRE6ynsZxj6+r7lXm3jfLR6tl5+7/0gV68y\n6qacUVeOzHU1yXr5xZd6Zehr0dd6H8tzJB2fnN7p2Hr7AEo63q2Hf0+GfkcMeUlep7/ODN/oM3t5\nhtfAS+M17uv357tOf81DP8k24CPACcDHq+r6udpOYujP9dUEC32BlrfhS+vXWh8EjpvQT3IC8L+B\nnwEOAvcB76mqh0e1Xy+hP1dgG9SShq1V+B9Pof/jwLVVdWlbvxqgqn59VPu1Cv25pkkkaS2s9MHg\nePrCtU3AgaH1g8BFww2S7AJ2tdXvJHl0Ga/3RuDZxTTMDct4lePDosc6IRzvZOtqvLlhxcf75rkq\njrvr9KvqZuDmldhWkum5jnaTpqexguOddI539az1JZuHgC1D65tbmSRpDax16N8HnJPkrCQnAlcC\nd65xHySpW2s6vVNVLyd5P3AXg0s2P1FVD63iS67INNE60dNYwfFOOse7So7rm7MkSSvLr2GQpI4Y\n+pLUkYkM/STbkjyaZH+S3ePuz2pI8mSSbyS5P8l0Kzstyd4kj7XHU8fdz6VK8okkh5M8OFQ2cnwZ\nuKnt7weSXDC+ni/NHOO9Nsmhto/vT3LZUN3VbbyPJrl0PL1euiRbknwpycNJHkrygVY+cft4nrGO\nZ/9W1UT9MPiA+HHgLcCJwNeB88bdr1UY55PAG2eV/Qawuy3vBm4Ydz+XMb6fBC4AHlxofMBlwP8A\nAlwM3Dvu/q/QeK8F/vOItue13+uTgLPa7/sJ4x7DMY73TOCCtvwGBl/Pct4k7uN5xjqW/TuJZ/oX\nAvur6q+q6u+AW4HtY+7TWtkO7GnLe4DLx9iXZamqPwWOziqea3zbgU/WwJeBU5KcuTY9XRlzjHcu\n24Fbq+qlqnoC2M/g937dqKqnquqrbflF4BEGd+xP3D6eZ6xzWdX9O4mhP+qrHuZ7g9erAr6QZF/7\n6gqAM6rqqbb8NHDGeLq2auYa3yTv8/e36YxPDE3XTdR4k2wFfhS4lwnfx7PGCmPYv5MY+r14e1Vd\nALwLeF+SnxyurMHfiRN7Pe6kj6/5GPDDwPnAU8Bvjrc7Ky/J64HPAB+sqr8erpu0fTxirGPZv5MY\n+l181UNVHWqPh4HPMvjz75mZP3nb4+Hx9XBVzDW+idznVfVMVb1SVd8Dfof//yf+RIw3yWsZhODv\nV9Uft+KJ3Mejxjqu/TuJoT/xX/WQ5OQkb5hZBi4BHmQwzh2t2Q7gjvH0cNXMNb47gavaFR4XAy8M\nTRGsW7PmrH+WwT6GwXivTHJSkrOAc4CvrHX/liNJgFuAR6rqt4aqJm4fzzXWse3fcX+yvUqfll/G\n4BPyx4FfHnd/VmF8b2Hw6f7XgYdmxgicDtwNPAZ8ETht3H1dxhj/kMGfvP+XwZzmzrnGx+CKjv/a\n9vc3gKlx93+FxvupNp4HWhCcOdT+l9t4HwXeNe7+L2G8b2cwdfMAcH/7uWwS9/E8Yx3L/vVrGCSp\nI5M4vSNJmoOhL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjry/wCXbzq/mOifigAAAABJRU5ErkJg\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s8g1y__hxIm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "5177453e-fec4-45e4-f9de-d381a001521b"
      },
      "source": [
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt \n",
        "import numpy as np\n",
        "f1=open(\"dat2.txt\",\"r+\")\n",
        "lines = f1.read().split('\\n')\n",
        "lines.pop()\n",
        "print(len(lines))\n",
        "\n",
        "# Convert the pixels into an array using numpy\n",
        "array = np.array(lines, dtype=np.uint8)\n",
        "\n",
        "# Use PIL to create an image from the new array of pixels\n",
        "new_image = Image.fromarray(array.reshape(250,250), 'L')\n",
        "new_image.save('new.png')\n",
        "\n",
        "im = Image.open(\"new.png\");\n",
        "pixel = list(im.getdata())\n",
        "a=np.array(pixel)\n",
        "print(a.shape)\n",
        "plt.hist(a, bins = 255)\n",
        "x1,x2,y1,y2 = plt.axis()\n",
        "\n",
        "plt.axis((x1,x2,0,5000))\n",
        "plt.title(\"histogram\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62500\n",
            "(62500,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nX5I6YuhLUkcMfUnqiKEvSR0x9CWpI/8PnYwDgpU1vT0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFXUpP4EXwQR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f0de6df-37de-480b-d2b3-28b0e5d7a5dc"
      },
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2200.000\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4400.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2200.000\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4400.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6CqHnS1tELF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "6f724e58-d239-428d-c7e6-317efbfea012"
      },
      "source": [
        "!lscpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               63\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2300.000\n",
            "BogoMIPS:            4600.00\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            46080K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb05JbiYTShH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "618129ab-3732-4fba-d8be-c1aa3ed6bd76"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h> \n",
        "\n",
        "int main() {\n",
        "  int nDevices;\n",
        "\n",
        "  cudaGetDeviceCount(&nDevices);\n",
        "  for (int i = 0; i < nDevices; i++) {\n",
        "    cudaDeviceProp prop;\n",
        "    cudaGetDeviceProperties(&prop, i);\n",
        "    printf(\"Device Number: %d\\n\", i);\n",
        "    printf(\"  Device name: %s\\n\", prop.name);\n",
        "    printf(\"  Memory Clock Rate (KHz): %d\\n\",\n",
        "           prop.memoryClockRate);\n",
        "    printf(\"  Memory Bus Width (bits): %d\\n\",\n",
        "           prop.memoryBusWidth);\n",
        "    printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n",
        "           2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
        "\n",
        "\n",
        "\n",
        "           int deviceCount;\n",
        "cudaGetDeviceCount(&deviceCount);\n",
        "int device;\n",
        "for (device = 0; device < deviceCount; ++device) {\n",
        "    cudaDeviceProp deviceProp;\n",
        "    cudaGetDeviceProperties(&deviceProp, device);\n",
        "    printf(\"Device %d has compute capability %d.%d.\\n\",\n",
        "           device, deviceProp.major, deviceProp.minor);\n",
        "}\n",
        "  }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device Number: 0\n",
            "  Device name: Tesla K80\n",
            "  Memory Clock Rate (KHz): 2505000\n",
            "  Memory Bus Width (bits): 384\n",
            "  Peak Memory Bandwidth (GB/s): 240.480000\n",
            "\n",
            "Device 0 has compute capability 3.7.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNuAzn01VCh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "18ec6d03-c9c2-4926-baf5-99cf64fe7b34"
      },
      "source": [
        "%%cu\n",
        "#include<cstdlib>\n",
        "#include<iostream>\n",
        "using namespace std;\n",
        "#include<cuda.h>\n",
        "#include<stdio.h>\n",
        "\n",
        "__global__ void histogramKernel(int *data,int *bins,long long int N, int N_bins)\n",
        "{\n",
        "\tint tid = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\tif(tid<N)\n",
        "\t{\n",
        "\t\tatomicAdd(&bins[data[tid]],1);\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void histogramKernelShared(int *data,int *bins,long long int N, int N_bins, float *binsnew)\n",
        "{\n",
        "\textern __shared__ int s_bins[];\n",
        "\tint tid = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\tif(threadIdx.x < N_bins)s_bins[threadIdx.x]=0;\n",
        "\t__syncthreads();\n",
        "\tif(tid<N)\n",
        "\t{\n",
        "\t\tatomicAdd(&s_bins[data[tid]],1);\n",
        "\t__syncthreads();\n",
        "\t\tif(threadIdx.x < N_bins)\n",
        "\t{\n",
        "\t\t\tatomicAdd(&bins[threadIdx.x],s_bins[threadIdx.x]);\n",
        "\t\t__syncthreads();\n",
        "\t\t__shared__ float s_binsnew[256];\n",
        "        s_binsnew[threadIdx.x]=0.00;\n",
        "       for(int i=0;i<=threadIdx.x;i++) s_binsnew[threadIdx.x]+=bins[i];\n",
        "      __syncthreads();\n",
        "       s_binsnew[threadIdx.x]=round((s_binsnew[threadIdx.x]/N)*N_bins-1);\n",
        "\t\t\t__syncthreads();\n",
        "       if (s_binsnew[threadIdx.x]>N_bins-1)s_binsnew[threadIdx.x]=N_bins-1;\n",
        "      __syncthreads();\n",
        "\t\tbinsnew[threadIdx.x] = s_binsnew[threadIdx.x];\n",
        "\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void mapHistogram(int *data,long long int N,float *binsnew)\n",
        "{\n",
        "\tint tid = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\tif(tid<N)data[tid]=binsnew[data[tid]];\n",
        "}\n",
        "\n",
        "void histEq(int *Data, int N, int *bins, int *Data2)\n",
        "{\n",
        "\t\tfloat binsf[256],binsf2[256];\n",
        "\t\tfor(int i=0;i<256;i++){binsf[i]=0;binsf2[i]=0;}\n",
        "\n",
        "\t\tfor(int i=0;i<N;i++)\n",
        "    \tbinsf[Data[i]]+=1.0;\n",
        "\t\tfor (int i=0;i<256;i++)\n",
        "\t\t{\n",
        "\t\tbinsf[i]/=N;\n",
        "\n",
        "\t\t\tfor(int j=0;j<=i;j++)\n",
        "\t\t\tbinsf2[i]+=binsf[j];\n",
        "\t\tbins[i]=(int)round(binsf2[i]*255);\n",
        "\t\t \n",
        "\t\t}\n",
        "\t\n",
        "\n",
        "\t\tfor(int i=0;i<N;i++)\n",
        "\t\t\tData2[i]=bins[Data[i]];\n",
        "}\n",
        "\n",
        "void init_array(int *a, int N)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=0;\n",
        "}\n",
        "\n",
        "void init_arrayf(float *a, int N)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=0;\n",
        "}\n",
        "\n",
        "void init_long_array(int *a,long long int N,int N_bins)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=rand()%N_bins;\n",
        "}\n",
        "\n",
        "void histogram(int *arr, int *bins, long long int N)\n",
        "{\n",
        "\tfor (long long int i=0;i<N;i++)\n",
        "\t{\n",
        "\t\tbins[arr[i]]++;\n",
        "\t}\n",
        "}\n",
        "\n",
        "void print_arr(int *arr, int N)\n",
        "{\n",
        "\tfor (int i=0;i<N;i++)\n",
        "\t{\n",
        "\t\t//if(arr[i]!=0)\n",
        "\t\t\tcout<<i<<\"->\"<<arr[i]<<endl;\n",
        "\t}\n",
        "\tcout<<endl;\n",
        "}\n",
        "\n",
        "void print_arrf(float *arr, int N)\n",
        "{\n",
        "\tfor (int i=0;i<N;i++)\n",
        "\t{\n",
        "\t\t//if(arr[i]!=0)\n",
        "\t\t\tcout<<i<<\"->\"<<arr[i]<<endl;\n",
        "\t}\n",
        "\tcout<<endl;\n",
        "}\n",
        "\n",
        "\n",
        "void print_long_arr(int *arr,long long int N)\n",
        "{\n",
        "\tfor (int i=0;i<N;i++)\n",
        "\t{\n",
        "\t\t//cout<<\"(\"<<i<<\",\"<<arr[i]<<\") \";\n",
        "\t\tcout<<arr[i]<<\" \";\n",
        "\t}\n",
        "\tcout<<endl;\n",
        "}\n",
        "\n",
        "void printSum(int *arr,int N)\n",
        "{\n",
        "\tlong long int sum=0;\n",
        "\tfor(int i=0;i<N;i++)sum+=arr[i];\n",
        "\tcout<<\"Verification of total is: \" << sum<<endl;\n",
        "}\n",
        "\n",
        "void printSumf(float *arr,int N)\n",
        "{\n",
        "\tfloat sum=0.0;\n",
        "\tfor(int i=0;i<N;i++)sum+=arr[i];\n",
        "\tcout<<\"Verification of total is: \" << sum<<endl;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\tint T=1024,B=1;\n",
        "\tint *Data,N_bins=256,*bins,*Data2;\n",
        "  bins = (int *)malloc(256*sizeof(int));\n",
        "\n",
        "\tlong long int N = 0;\n",
        "FILE *serTimeEx = fopen(\"serialTimeExecution.txt\",\"w\");\n",
        "FILE *parTimeEx = fopen(\"parallelTimeExecution.txt\",\"w\");\n",
        "FILE *speedupEx = fopen(\"speedup.txt\",\"w\");\n",
        "FILE *exTable = fopen(\"Execution.txt\",\"w\");\n",
        "\n",
        "\tfor(N=256;N<134217729;N*=2)\n",
        "\t{\n",
        "    Data = (int *)malloc(N*sizeof(int));\n",
        "    Data2 = (int *)malloc(N*sizeof(int));\n",
        "    init_long_array(Data,N,N_bins);\n",
        "    init_long_array(Data2,N,N_bins);\n",
        "\t\tinit_array(bins,N_bins);\n",
        "    B = (N+T-1)/T;\n",
        "    cudaEvent_t ss,se;\n",
        "\t  float st,st2;\n",
        "\n",
        "cudaEventCreate(&ss); \n",
        "\t\t\t\tcudaEventCreate(&se);\n",
        "\t\t\t\tcudaEventRecord(ss);\n",
        "\t\t\t\tcudaDeviceSynchronize();\n",
        "\t        histEq(Data,N,bins,Data2);\n",
        "\t\t\t\tcudaEventRecord(se);\n",
        "\t\t\t\tcudaEventSynchronize(se);\n",
        "\t\t\t\tcudaEventElapsedTime(&st, ss, se);\n",
        "\n",
        "\t\tint *dev_Data2,*dev_bins2;\n",
        "\t\tfloat *dev_bins22,*bins2;\n",
        "\t\tbins2 = (float *)malloc(N_bins*sizeof(float));\n",
        "\n",
        "\t\tinit_arrayf(bins2,N_bins);\n",
        "\t\tcudaMalloc((void**)&dev_Data2,N*sizeof(int));\n",
        "\t\tcudaMalloc((void**)&dev_bins2,N_bins*sizeof(int));\n",
        "\t\tcudaMalloc((void**)&dev_bins22,N_bins*sizeof(float));\n",
        "\n",
        "\t\tcudaMemcpy(dev_Data2, Data , N*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\t\tcudaMemcpy(dev_bins2, bins , N_bins*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\t\tcudaMemcpy(dev_bins22, bins2 , N_bins*sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "\t\tcudaEventCreate(&ss); \n",
        "\t\t\t\t\tcudaEventCreate(&se);\n",
        "\t\t\t\t\tcudaEventRecord(ss);\n",
        "\t\t\t\t\tcudaDeviceSynchronize();\n",
        "\t\t\n",
        "\t\t\t\t\t\thistogramKernelShared<<<B,T,N_bins*sizeof(int)>>>(dev_Data2,dev_bins2,N,N_bins,dev_bins22);\n",
        "\t\t\t\t\t\tmapHistogram<<<B,T>>>(dev_Data2,N,dev_bins22);\n",
        "\n",
        "\t\t\t\t\tcudaEventRecord(se);\n",
        "\t\t\t\t\tcudaEventSynchronize(se);\n",
        "\t\t\t\t\tcudaEventElapsedTime(&st2, ss, se);\n",
        "\t\t\n",
        "cout<<N<<\"  \"<<st<<\" \"<<st2<<\" \"<<st/st2<<endl;\n",
        "\n",
        "\n",
        "fprintf(serTimeEx,\"%d\\t%f\\n\",N,st);\n",
        "fprintf(parTimeEx,\"%d\\t%f\\n\",N,st2);\n",
        "fprintf(speedupEx,\"%d\\t%f\\n\",N,st/st2);\n",
        "fprintf(exTable,\"%d\\t%f\\t%f\\t%f\\n\",N,st,st2,st/st2);\n",
        "\n",
        "\t\tcudaMemcpy(bins,dev_bins2,N_bins*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\t\tcudaMemcpy(bins2,dev_bins22,N_bins*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\t\tcudaMemcpy(Data,dev_Data2,N*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "  \n",
        "\t\tcudaFree(dev_Data2);cudaFree(dev_bins2);cudaFree(dev_bins22);\n",
        "\t\tfree(bins2);\n",
        "\t}\n",
        "  fclose(serTimeEx);fclose(parTimeEx);fclose(speedupEx);fclose(exTable);\n",
        "\tfree(Data);free(bins);\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256  0.121888 0.144544 0.843259\n",
            "512  0.123648 0.06672 1.85324\n",
            "1024  0.1296 0.06528 1.98529\n",
            "2048  0.133184 0.067904 1.96136\n",
            "4096  0.145664 0.070016 2.08044\n",
            "8192  0.172608 0.071744 2.40589\n",
            "16384  0.223936 0.079904 2.80256\n",
            "32768  0.33584 0.114304 2.93813\n",
            "65536  0.546048 0.172384 3.16763\n",
            "131072  0.963584 0.263136 3.66192\n",
            "262144  1.82 0.455584 3.99487\n",
            "524288  3.50323 0.85024 4.12029\n",
            "1048576  7.19626 1.6168 4.45093\n",
            "2097152  14.2122 3.14346 4.52119\n",
            "4194304  27.9899 6.18944 4.5222\n",
            "8388608  55.6754 12.2732 4.53634\n",
            "16777216  135.165 24.451 5.52801\n",
            "33554432  225.846 48.7902 4.62891\n",
            "67108864  460.097 97.5247 4.71775\n",
            "134217728  896.339 167.731 5.34391\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIzn8SFzBpb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "77e1a6a7-3efd-4af1-dbed-300a3a353ac8"
      },
      "source": [
        "%%cu\n",
        "#include<cstdlib>\n",
        "#include<iostream>\n",
        "using namespace std;\n",
        "#include<cuda.h>\n",
        "#include<stdio.h>\n",
        "\n",
        "__global__ void histogramKernel(int *data,int *bins,long long int N, int N_bins)\n",
        "{\n",
        "\tint tid = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\tif(tid<N)\n",
        "\t{\n",
        "\t\tatomicAdd(&bins[data[tid]],1);\n",
        "\t}\n",
        "  for(int i=0;i<100000;i++){}\n",
        "}\n",
        "\n",
        "__global__ void histogramKernelShared(int *data,int *bins,long long int N, int N_bins, float *binsnew)\n",
        "{\n",
        "\textern __shared__ int s_bins[];\n",
        "\tint tid = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\tif(threadIdx.x < N_bins)s_bins[threadIdx.x]=0;\n",
        "\t__syncthreads();\n",
        "\tif(tid<N)\n",
        "\t{\n",
        "\t\tatomicAdd(&s_bins[data[tid]],1);\n",
        "\t__syncthreads();\n",
        "\t\tif(threadIdx.x < N_bins)\n",
        "\t  {\n",
        "\t\t\tatomicAdd(&bins[threadIdx.x],s_bins[threadIdx.x]);\n",
        "    }\n",
        "\t}\n",
        "}\n",
        "\n",
        "void print_arr(int *arr, int N)\n",
        "{\n",
        "\tfor (int i=0;i<N;i++)\n",
        "\t{\n",
        "\t\t//if(arr[i]!=0)\n",
        "\t\t\tcout<<i<<\"->\"<<arr[i]<<endl;\n",
        "\t}\n",
        "\tcout<<endl;\n",
        "}\n",
        "\n",
        "void init_array(int *a, int N)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=0;\n",
        "}\n",
        "\n",
        "void init_arrayf(float *a, int N)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=0;\n",
        "}\n",
        "\n",
        "void init_long_array(int *a,long long int N,int N_bins)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=rand()%N_bins;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "\tint T=1024,B=1;\n",
        "\tint *Data,N_bins=256,*bins,*Data2;\n",
        "  bins = (int *)malloc(N_bins*sizeof(int));\n",
        "\n",
        "\tlong long int N = 0;\n",
        "FILE *shaHistEx = fopen(\"sharedHistogramExecution.txt\",\"w\");\n",
        "FILE *gloHistEx = fopen(\"globalHistogramExecution.txt\",\"w\");\n",
        "\n",
        "\tfor(N=256;N<134217729;N*=2)//134217729\n",
        "\t{\n",
        "    Data = (int *)malloc(N*sizeof(int));\n",
        "    Data2 = (int *)malloc(N*sizeof(int));\n",
        "    init_long_array(Data,N,N_bins);\n",
        "    init_long_array(Data2,N,N_bins);\n",
        "\t\tinit_array(bins,N_bins);\n",
        "    B = (N+T-1)/T;\n",
        "    cudaEvent_t ss,se;\n",
        "\t  float st,st2;\n",
        " int *dev_Data,*dev_bins;\n",
        "\t\tcudaMalloc((void**)&dev_Data,N*sizeof(int));\n",
        "\t\tcudaMalloc((void**)&dev_bins,N_bins*sizeof(int));\n",
        "\t\tcudaMemcpy(dev_Data, Data , N*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\t\tcudaMemcpy(dev_bins, bins , N_bins*sizeof(int),cudaMemcpyHostToDevice);\n",
        "cudaEventCreate(&ss); \n",
        "\t\t\t\tcudaEventCreate(&se);\n",
        "\t\t\t\tcudaEventRecord(ss);\n",
        "\t\t\t\tcudaDeviceSynchronize();\n",
        "\t        histogramKernel<<<B,T>>>(dev_Data,dev_bins,N,N_bins);\n",
        "\t\t\t\tcudaEventRecord(se);\n",
        "\t\t\t\tcudaEventSynchronize(se);\n",
        "\t\t\t\tcudaEventElapsedTime(&st, ss, se);\n",
        "    cudaMemcpy(bins,dev_bins,N_bins*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\t\tcudaMemcpy(Data,dev_Data,N*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "cudaFree(dev_Data);cudaFree(dev_bins);\n",
        "\t\tint *dev_Data2,*dev_bins2;\n",
        "\t\tfloat *dev_bins22,*bins2;\n",
        "\t\tbins2 = (float *)malloc(N_bins*sizeof(float));\n",
        "\t\tinit_array(bins,N_bins);\n",
        "\t\tinit_arrayf(bins2,N_bins);\n",
        "  \n",
        "\t\tcudaMalloc((void**)&dev_Data2,N*sizeof(int));\n",
        "\t\tcudaMalloc((void**)&dev_bins2,N_bins*sizeof(int));\n",
        "\t\tcudaMalloc((void**)&dev_bins22,N_bins*sizeof(float));\n",
        "\n",
        "\t\tcudaMemcpy(dev_Data2, Data , N*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\t\tcudaMemcpy(dev_bins2, bins , N_bins*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\t\tcudaMemcpy(dev_bins22, bins2 , N_bins*sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "\t\tcudaEventCreate(&ss); \n",
        "\t\t\t\t\tcudaEventCreate(&se);\n",
        "\t\t\t\t\tcudaEventRecord(ss);\n",
        "\t\t\t\t\tcudaDeviceSynchronize();\n",
        "\t\t\n",
        "\t\t\t\t\t\thistogramKernelShared<<<B,T,N_bins*sizeof(int)>>>(dev_Data2,dev_bins2,N,N_bins,dev_bins22);\n",
        "\n",
        "\t\t\t\t\tcudaEventRecord(se);\n",
        "\t\t\t\t\tcudaEventSynchronize(se);\n",
        "\t\t\t\t\tcudaEventElapsedTime(&st2, ss, se);\n",
        "\t\t\n",
        "cout<<N<<\"  \"<<st<<\" \"<<st2<<\" \"<<st/st2<<endl;\n",
        "\n",
        "fprintf(shaHistEx,\"%d\\t%f\\n\",N,st2);\n",
        "fprintf(gloHistEx,\"%d\\t%f\\n\",N,st);\n",
        "\t\tcudaMemcpy(bins,dev_bins2,N_bins*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\t\tcudaMemcpy(bins2,dev_bins22,N_bins*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\t\tcudaMemcpy(Data,dev_Data2,N*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "  \n",
        "\t\tcudaFree(dev_Data2);cudaFree(dev_bins2);cudaFree(dev_bins22);\n",
        "\t\tfree(bins2);\n",
        "\t}\n",
        "  fclose(shaHistEx);fclose(gloHistEx);\n",
        "\tfree(Data);free(bins);\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256  0.088512 0.03248 2.72512\n",
            "512  0.027968 0.029888 0.93576\n",
            "1024  0.025248 0.02912 0.867033\n",
            "2048  0.028608 0.030592 0.935146\n",
            "4096  0.028416 0.0304 0.934737\n",
            "8192  0.030304 0.030496 0.993704\n",
            "16384  0.028736 0.031168 0.921971\n",
            "32768  0.0336 0.033312 1.00865\n",
            "65536  0.03936 0.039072 1.00737\n",
            "131072  0.05056 0.050688 0.997475\n",
            "262144  0.076 0.072224 1.05228\n",
            "524288  0.122336 0.119008 1.02796\n",
            "1048576  0.222432 0.208992 1.06431\n",
            "2097152  0.397632 0.380544 1.0449\n",
            "4194304  0.74336 0.72896 1.01975\n",
            "8388608  1.47098 1.43933 1.02199\n",
            "16777216  2.89955 2.83942 1.02118\n",
            "33554432  5.75715 5.63216 1.02219\n",
            "67108864  11.2612 11.2263 1.0031\n",
            "134217728  20.1928 15.7017 1.28603\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clf7egOOl59u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "4c5eb74d-4704-4d8a-98b9-e3df80854101"
      },
      "source": [
        "%%cu\n",
        "#include<cstdlib>\n",
        "#include<iostream>\n",
        "using namespace std;\n",
        "#include<cuda.h>\n",
        "#include<stdio.h>\n",
        "\n",
        "__global__ void histogramKernelShared(int *data,int *bins,long long int N, int N_bins, float *binsnew)\n",
        "{\n",
        "\textern __shared__ int s_bins[];\n",
        "\tint tid = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\tif(threadIdx.x < N_bins)s_bins[threadIdx.x]=0;\n",
        "\t__syncthreads();\n",
        "\tif(tid<N)\n",
        "\t{\n",
        "\t\tatomicAdd(&s_bins[data[tid]],1);\n",
        "\t__syncthreads();\n",
        "\t\tif(threadIdx.x < N_bins)\n",
        "\t{\n",
        "\t\t\tatomicAdd(&bins[threadIdx.x],s_bins[threadIdx.x]);\n",
        "\t\t__syncthreads();\n",
        "\t\t__shared__ float s_binsnew[256];\n",
        "        s_binsnew[threadIdx.x]=0.00;\n",
        "       for(int i=0;i<=threadIdx.x;i++) s_binsnew[threadIdx.x]+=bins[i];\n",
        "      __syncthreads();\n",
        "       s_binsnew[threadIdx.x]=round((s_binsnew[threadIdx.x]/N)*N_bins-1);\n",
        "\t\t\t__syncthreads();\n",
        "       if (s_binsnew[threadIdx.x]>N_bins-1)s_binsnew[threadIdx.x]=N_bins-1;\n",
        "      __syncthreads();\n",
        "\t\tbinsnew[threadIdx.x] = s_binsnew[threadIdx.x];\n",
        "\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void mapHistogram(int *data,long long int N,float *binsnew)\n",
        "{\n",
        "\tint tid = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\tif(tid<N)data[tid]=binsnew[data[tid]];\n",
        "}\n",
        "\n",
        "\n",
        "void init_array(int *a, int N)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=0;\n",
        "}\n",
        "\n",
        "void init_arrayf(float *a, int N)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=0;\n",
        "}\n",
        "\n",
        "void init_long_array(int *a,long long int N,int N_bins)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=rand()%N_bins;\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "\tint T=1024,B=1;\n",
        "\tint *Data,N_bins=256,*bins,*Data2;\n",
        "  bins = (int *)malloc(256*sizeof(int));\n",
        "FILE *totalParTime = fopen(\"totalPar.txt\",\"w\");\n",
        "\tlong long int N = 0;\n",
        "\n",
        "\tfor(N=256;N<134217729;N*=2)//134217729\n",
        "\t{\n",
        "    Data = (int *)malloc(N*sizeof(int));\n",
        "    Data2 = (int *)malloc(N*sizeof(int));\n",
        "    init_long_array(Data,N,N_bins);\n",
        "    init_long_array(Data2,N,N_bins);\n",
        "\t\tinit_array(bins,N_bins);\n",
        "    B = (N+T-1)/T;\n",
        "    cudaEvent_t ss,se;\n",
        "\t  float st,st2,st3;\n",
        "\n",
        "\t\tint *dev_Data2,*dev_bins2;\n",
        "\t\tfloat *dev_bins22,*bins2;\n",
        "\t\tbins2 = (float *)malloc(N_bins*sizeof(float));\n",
        "\n",
        "\t\tinit_arrayf(bins2,N_bins);\n",
        "\t\tcudaMalloc((void**)&dev_Data2,N*sizeof(int));\n",
        "\t\tcudaMalloc((void**)&dev_bins2,N_bins*sizeof(int));\n",
        "\t\tcudaMalloc((void**)&dev_bins22,N_bins*sizeof(float));\n",
        "\n",
        "cudaEventCreate(&ss); \n",
        "\t\t\t\t\tcudaEventCreate(&se);\n",
        "\t\t\t\t\tcudaEventRecord(ss);\n",
        "\t\t\t\t\tcudaDeviceSynchronize();\n",
        "\t\tcudaMemcpy(dev_Data2, Data , N*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\t\tcudaMemcpy(dev_bins2, bins , N_bins*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\t\tcudaMemcpy(dev_bins22, bins2 , N_bins*sizeof(float),cudaMemcpyHostToDevice);\n",
        "cudaEventRecord(se);\n",
        "cudaEventSynchronize(se);\n",
        "cudaEventElapsedTime(&st, ss, se);\n",
        "\t\t\n",
        "\n",
        "    cudaEventCreate(&ss); \n",
        "\t\t\t\t\tcudaEventCreate(&se);\n",
        "\t\t\t\t\tcudaEventRecord(ss);\n",
        "\t\t\t\t\tcudaDeviceSynchronize();\n",
        "\t\t\t\t\t\thistogramKernelShared<<<B,T,N_bins*sizeof(int)>>>(dev_Data2,dev_bins2,N,N_bins,dev_bins22);\n",
        "\t\t\t\t\t\tmapHistogram<<<B,T>>>(dev_Data2,N,dev_bins22);\n",
        "cudaEventRecord(se);\n",
        "cudaEventSynchronize(se);\n",
        "cudaEventElapsedTime(&st3, ss, se);\n",
        "\t\t\n",
        "cudaEventCreate(&ss); \n",
        "\t\t\t\t\tcudaEventCreate(&se);\n",
        "\t\t\t\t\tcudaEventRecord(ss);\n",
        "\t\t\t\t\tcudaDeviceSynchronize();\n",
        "\t\tcudaMemcpy(bins,dev_bins2,N_bins*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\t\tcudaMemcpy(bins2,dev_bins22,N_bins*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\t\tcudaMemcpy(Data,dev_Data2,N*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "    \n",
        "cudaEventRecord(se);\n",
        "cudaEventSynchronize(se);\n",
        "cudaEventElapsedTime(&st2, ss, se);\n",
        "\n",
        "  cout<<N<<\"  \"<<st<<\" \"<<st2<<\" \"<<st3<<\" \"<<st+st2+st3<<endl;\n",
        "fprintf(totalParTime,\"%d  %f  %f  %f  %f\\n\",N,st,st2,st3,st+st2+st3);\n",
        "\t\tcudaFree(dev_Data2);cudaFree(dev_bins2);cudaFree(dev_bins22);\n",
        "\t\tfree(bins2);\n",
        "\t}\n",
        " fclose(totalParTime);\n",
        "\tfree(Data);free(bins);\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256  0.043456 0.062304 0.126944 0.232704\n",
            "512  0.043744 0.049696 0.0632 0.15664\n",
            "1024  0.041984 0.068256 0.06592 0.17616\n",
            "2048  0.040032 0.050496 0.072704 0.163232\n",
            "4096  0.049248 0.05248 0.068704 0.170432\n",
            "8192  0.056032 0.087648 0.0712 0.21488\n",
            "16384  0.069472 0.067328 0.079616 0.216416\n",
            "32768  0.077152 0.084672 0.114912 0.276736\n",
            "65536  0.11568 0.124 0.165024 0.404704\n",
            "131072  0.1984 0.226432 0.264 0.688832\n",
            "262144  0.365408 0.340864 0.466848 1.17312\n",
            "524288  0.48864 0.535616 0.852704 1.87696\n",
            "1048576  0.78256 0.71184 1.62576 3.12016\n",
            "2097152  1.512 1.2703 3.16038 5.94269\n",
            "4194304  2.51846 2.34032 6.23779 11.0966\n",
            "8388608  4.69661 4.61312 12.3779 21.6876\n",
            "16777216  9.23539 8.80758 24.6647 42.7077\n",
            "33554432  18.1441 17.5052 49.2543 84.9035\n",
            "67108864  36.2116 31.1667 97.549 164.927\n",
            "134217728  71.0009 56.9725 175.489 303.463\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdPtBpltd9mA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "outputId": "4d7fba91-0eb5-435b-9a79-a37c39b353f7"
      },
      "source": [
        "%%cu\n",
        "#include<cstdlib>\n",
        "#include<iostream>\n",
        "using namespace std;\n",
        "#include<cuda.h>\n",
        "#include<stdio.h>\n",
        "\n",
        "__global__ void histogramKernel(int *data,int *bins,long long int N, int N_bins)\n",
        "{\n",
        "\tint tid = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\tif(tid<N)\n",
        "\t{\n",
        "\t\tatomicAdd(&bins[data[tid]],1);\n",
        "\t}\n",
        "  for(int i=0;i<100000;i++){}\n",
        "}\n",
        "\n",
        "__global__ void histogramKernelShared(int *data,int *bins,long long int N, int N_bins, float *binsnew)\n",
        "{\n",
        "\textern __shared__ int s_bins[];\n",
        "\tint tid = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\tif(threadIdx.x < N_bins)s_bins[threadIdx.x]=0;\n",
        "\t__syncthreads();\n",
        "\tif(tid<N)\n",
        "\t{\n",
        "\t\tatomicAdd(&s_bins[data[tid]],1);\n",
        "\t__syncthreads();\n",
        "\t\tif(threadIdx.x < N_bins)\n",
        "\t  {\n",
        "\t\t\tatomicAdd(&bins[threadIdx.x],s_bins[threadIdx.x]);\n",
        "    }\n",
        "\t}\n",
        "}\n",
        "\n",
        "void print_arr(int *arr, int N)\n",
        "{\n",
        "\tfor (int i=0;i<N;i++)\n",
        "\t{\n",
        "\t\t//if(arr[i]!=0)\n",
        "\t\t\tcout<<i<<\"->\"<<arr[i]<<endl;\n",
        "\t}\n",
        "\tcout<<endl;\n",
        "}\n",
        "\n",
        "void init_array(int *a, int N)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=0;\n",
        "}\n",
        "\n",
        "void init_arrayf(float *a, int N)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=0;\n",
        "}\n",
        "\n",
        "void init_long_array(int *a,long long int N,int N_bins)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=255;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\tint T=1024,B=1;\n",
        "\tint *Data,N_bins=256,*bins,*Data2;\n",
        "  bins = (int *)malloc(N_bins*sizeof(int));\n",
        "\n",
        "\tlong long int N = 0;\n",
        "FILE *sha_gloHistEx = fopen(\"shared-globalHistogramExecutionBest.txt\",\"w\");\n",
        "\n",
        "\tfor(N=256;N<134217729;N*=2)//134217729\n",
        "\t{\n",
        "\t\t\tcout<<\"N is \"<<N<<endl;\n",
        "    Data = (int *)malloc(N*sizeof(int));\n",
        "    Data2 = (int *)malloc(N*sizeof(int));\n",
        "    init_long_array(Data,N,N_bins);\n",
        "    init_long_array(Data2,N,N_bins);\n",
        "\t\tinit_array(bins,N_bins);\n",
        "    B = (N+T-1)/T;\n",
        "    cudaEvent_t ss,se;\n",
        "\t  float st,st2;\n",
        " int *dev_Data,*dev_bins;\n",
        "\t\tcudaMalloc((void**)&dev_Data,N*sizeof(int));\n",
        "\t\tcudaMalloc((void**)&dev_bins,N_bins*sizeof(int));\n",
        "\t\tcudaMemcpy(dev_Data, Data , N*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\t\tcudaMemcpy(dev_bins, bins , N_bins*sizeof(int),cudaMemcpyHostToDevice);\n",
        "cudaEventCreate(&ss); \n",
        "\t\t\t\tcudaEventCreate(&se);\n",
        "\t\t\t\tcudaEventRecord(ss);\n",
        "\t\t\t\tcudaDeviceSynchronize();\n",
        "\t        histogramKernel<<<B,T>>>(dev_Data,dev_bins,N,N_bins);\n",
        "\t\t\t\tcudaEventRecord(se);\n",
        "\t\t\t\tcudaEventSynchronize(se);\n",
        "\t\t\t\tcudaEventElapsedTime(&st, ss, se);\n",
        "    cudaMemcpy(bins,dev_bins,N_bins*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\t\tcudaMemcpy(Data,dev_Data,N*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\t\t\n",
        "cudaFree(dev_Data);cudaFree(dev_bins);\n",
        "\t\tint *dev_Data2,*dev_bins2;\n",
        "\t\tfloat *dev_bins22,*bins2;\n",
        "\t\tbins2 = (float *)malloc(N_bins*sizeof(float));\n",
        "\t\tinit_array(bins,N_bins);\n",
        "\t\tinit_arrayf(bins2,N_bins);\n",
        "  \n",
        "\t\tcudaMalloc((void**)&dev_Data2,N*sizeof(int));\n",
        "\t\tcudaMalloc((void**)&dev_bins2,N_bins*sizeof(int));\n",
        "\t\tcudaMalloc((void**)&dev_bins22,N_bins*sizeof(float));\n",
        "\n",
        "\t\tcudaMemcpy(dev_Data2, Data , N*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\t\tcudaMemcpy(dev_bins2, bins , N_bins*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\t\tcudaMemcpy(dev_bins22, bins2 , N_bins*sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "\t\tcudaEventCreate(&ss); \n",
        "\t\t\t\t\tcudaEventCreate(&se);\n",
        "\t\t\t\t\tcudaEventRecord(ss);\n",
        "\t\t\t\t\tcudaDeviceSynchronize();\n",
        "\t\t\n",
        "\t\t\t\t\t\thistogramKernelShared<<<B,T,N_bins*sizeof(int)>>>(dev_Data2,dev_bins2,N,N_bins,dev_bins22);\n",
        "\n",
        "\t\t\t\t\tcudaEventRecord(se);\n",
        "\t\t\t\t\tcudaEventSynchronize(se);\n",
        "\t\t\t\t\tcudaEventElapsedTime(&st2, ss, se);\n",
        "\t\t\n",
        "cout<<N<<\"  \"<<st2<<\" \"<<st<<\" \"<<st/st2<<endl;\n",
        "\n",
        "fprintf(sha_gloHistEx,\"%10d %10f %10f\\n\",N,st2,st);\n",
        "\n",
        "\t\tcudaMemcpy(bins,dev_bins2,N_bins*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\t\tcudaMemcpy(bins2,dev_bins22,N_bins*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\t\tcudaMemcpy(Data,dev_Data2,N*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "  \n",
        "\t\tcudaFree(dev_Data2);cudaFree(dev_bins2);cudaFree(dev_bins22);\n",
        "\t\tfree(bins2);\n",
        "\t}\n",
        "  fclose(sha_gloHistEx);\n",
        "\tfree(Data);free(bins);\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N is 256\n",
            "256  0.067488 0.083232 1.23329\n",
            "N is 512\n",
            "512  0.0896 0.027776 0.31\n",
            "N is 1024\n",
            "1024  0.115584 0.028672 0.248062\n",
            "N is 2048\n",
            "2048  0.119424 0.0312 0.261254\n",
            "N is 4096\n",
            "4096  0.116576 0.03568 0.306066\n",
            "N is 8192\n",
            "8192  0.118432 0.04112 0.347203\n",
            "N is 16384\n",
            "16384  0.153952 0.08592 0.558096\n",
            "N is 32768\n",
            "32768  0.244576 0.089664 0.36661\n",
            "N is 65536\n",
            "65536  0.38848 0.152064 0.391433\n",
            "N is 131072\n",
            "131072  0.644288 0.27376 0.424903\n",
            "N is 262144\n",
            "262144  1.24042 0.51952 0.418827\n",
            "N is 524288\n",
            "524288  2.45949 1.01232 0.411598\n",
            "N is 1048576\n",
            "1048576  4.84058 1.99798 0.412757\n",
            "N is 2097152\n",
            "2097152  9.63344 3.96419 0.411503\n",
            "N is 4194304\n",
            "4194304  19.1832 7.88938 0.411264\n",
            "N is 8388608\n",
            "8388608  38.3437 15.7485 0.41072\n",
            "N is 16777216\n",
            "16777216  76.6161 31.5064 0.411225\n",
            "N is 33554432\n",
            "33554432  141.283 57.5679 0.407466\n",
            "N is 67108864\n",
            "67108864  219.786 104.11 0.473689\n",
            "N is 134217728\n",
            "134217728  400.688 161.567 0.403223\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0_eoRo1moEc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "outputId": "1d1af8c6-2498-421d-fde7-5cad88cd2338"
      },
      "source": [
        "%%cu\n",
        "#include<cstdlib>\n",
        "#include<iostream>\n",
        "#include<cuda.h>\n",
        "#include<stdio.h>\n",
        "using namespace std;\n",
        "\n",
        "__global__ void histogramKernelShared(int *data,int *bins,long long int N, int N_bins, float *binsnew)\n",
        "{\n",
        "\textern __shared__ int s_bins[];\n",
        "\tint tid = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "\tif(threadIdx.x < N_bins)s_bins[threadIdx.x]=0;\n",
        "\t__syncthreads();\n",
        "\tif(tid<N)\n",
        "\t{\n",
        "\t\tatomicAdd(&s_bins[data[tid]],1);\n",
        "\t__syncthreads();\n",
        "\t\tif(threadIdx.x < N_bins)\n",
        "\t  {\n",
        "\t\t\tatomicAdd(&bins[threadIdx.x],s_bins[threadIdx.x]);\n",
        "    }\n",
        "\t}\n",
        "}\n",
        "\n",
        "void histCreate(int *Data, long long int N, int *bins)\n",
        "{\n",
        "    for(int i=0;i<N;i++)\n",
        "      bins[Data[i]]+=1;\n",
        "}\n",
        "\n",
        "void print_arr(int *arr, int N)\n",
        "{\n",
        "\tfor (int i=0;i<N;i++)\n",
        "\t{\n",
        "\t\t//if(arr[i]!=0)\n",
        "\t\t\tcout<<i<<\"->\"<<arr[i]<<endl;\n",
        "\t}\n",
        "\tcout<<endl;\n",
        "}\n",
        "\n",
        "void init_array(int *a, int N)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=0;\n",
        "}\n",
        "\n",
        "void init_arrayf(float *a, int N)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=0;\n",
        "}\n",
        "\n",
        "void init_long_array(int *a,long long int N,int N_bins)\n",
        "{\n",
        "\tfor(int i=0;i<N;i++)a[i]=rand()%N_bins;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\tint T=1024,B=1;\n",
        "\tint *Data,N_bins=256,*bins,*Data2;\n",
        "  bins = (int *)malloc(N_bins*sizeof(int));\n",
        "\n",
        "\tlong long int N = 0;\n",
        "FILE *histSer = fopen(\"histSer.txt\",\"w\");\n",
        "FILE *histPar = fopen(\"histPar.txt\",\"w\");\n",
        "FILE *speedHist = fopen(\"speedHist.txt\",\"w\");\n",
        "\n",
        "\tfor(N=256;N<134217729;N*=2)//134217729\n",
        "\t{\n",
        "\t\t\tcout<<\"N is \"<<N<<endl;\n",
        "    Data = (int *)malloc(N*sizeof(int));\n",
        "    Data2 = (int *)malloc(N*sizeof(int));\n",
        "    init_long_array(Data,N,N_bins);\n",
        "    init_long_array(Data2,N,N_bins);\n",
        "\t\tinit_array(bins,N_bins);\n",
        "    B = (N+T-1)/T;\n",
        "    cudaEvent_t ss,se;\n",
        "\t  float st,st2;\n",
        "\n",
        "cudaEventCreate(&ss); \n",
        "\t\t\t\tcudaEventCreate(&se);\n",
        "\t\t\t\tcudaEventRecord(ss);\n",
        "\t\t\t\tcudaDeviceSynchronize();\n",
        "           histCreate(Data,N,bins);\n",
        "\t\t\t\tcudaEventRecord(se);\n",
        "\t\t\t\tcudaEventSynchronize(se);\n",
        "\t\t\t\tcudaEventElapsedTime(&st, ss, se);\n",
        "\t\t\n",
        "\t\tint *dev_Data2,*dev_bins2;\n",
        "\t\tfloat *dev_bins22,*bins2;\n",
        "\t\tbins2 = (float *)malloc(N_bins*sizeof(float));\n",
        "\t\tinit_array(bins,N_bins);\n",
        "\t\tinit_arrayf(bins2,N_bins);\n",
        "  \n",
        "\t\tcudaMalloc((void**)&dev_Data2,N*sizeof(int));\n",
        "\t\tcudaMalloc((void**)&dev_bins2,N_bins*sizeof(int));\n",
        "\t\tcudaMalloc((void**)&dev_bins22,N_bins*sizeof(float));\n",
        "\n",
        "\t\tcudaMemcpy(dev_Data2, Data , N*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\t\tcudaMemcpy(dev_bins2, bins , N_bins*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\t\tcudaMemcpy(dev_bins22, bins2 , N_bins*sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "\t\tcudaEventCreate(&ss); \n",
        "\t\t\t\t\tcudaEventCreate(&se);\n",
        "\t\t\t\t\tcudaEventRecord(ss);\n",
        "\t\t\t\t\tcudaDeviceSynchronize();\n",
        "\t\t\n",
        "\t\t\t\t\t\thistogramKernelShared<<<B,T,N_bins*sizeof(int)>>>(dev_Data2,dev_bins2,N,N_bins,dev_bins22);\n",
        "\n",
        "\t\t\t\t\tcudaEventRecord(se);\n",
        "\t\t\t\t\tcudaEventSynchronize(se);\n",
        "\t\t\t\t\tcudaEventElapsedTime(&st2, ss, se);\n",
        "\t\t\n",
        "cout<<N<<\"  \"<<st<<\" \"<<st2<<\" \"<<st/st2<<endl;\n",
        "\n",
        "fprintf(histSer,\"%d\\t%f\\n\",N,st);\n",
        "fprintf(histPar,\"%d\\t%f\\n\",N,st2);\n",
        "fprintf(speedHist,\"%d\\t%f\\n\",N,st/st2);\n",
        "\n",
        "\n",
        "\t\tcudaMemcpy(bins,dev_bins2,N_bins*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\t\tcudaMemcpy(bins2,dev_bins22,N_bins*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "\t\tcudaMemcpy(Data,dev_Data2,N*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "  \n",
        "\t\tcudaFree(dev_Data2);cudaFree(dev_bins2);cudaFree(dev_bins22);\n",
        "\t\tfree(bins2);\n",
        "\t}\n",
        "  fclose(histSer);fclose(histPar);fclose(speedHist);\n",
        "\tfree(Data);free(bins);\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N is 256\n",
            "256  0.01616 0.113536 0.142334\n",
            "N is 512\n",
            "512  0.01744 0.03392 0.514151\n",
            "N is 1024\n",
            "1024  0.02368 0.036064 0.65661\n",
            "N is 2048\n",
            "2048  0.026784 0.037696 0.710526\n",
            "N is 4096\n",
            "4096  0.026208 0.031168 0.840862\n",
            "N is 8192\n",
            "8192  0.040288 0.033056 1.21878\n",
            "N is 16384\n",
            "16384  0.111872 0.033472 3.34226\n",
            "N is 32768\n",
            "32768  0.123328 0.034816 3.54228\n",
            "N is 65536\n",
            "65536  0.273888 0.04912 5.5759\n",
            "N is 131072\n",
            "131072  0.464352 0.050272 9.23679\n",
            "N is 262144\n",
            "262144  0.91296 0.072384 12.6127\n",
            "N is 524288\n",
            "524288  1.90141 0.118944 15.9857\n",
            "N is 1048576\n",
            "1048576  3.60749 0.208192 17.3277\n",
            "N is 2097152\n",
            "2097152  7.2704 0.388896 18.695\n",
            "N is 4194304\n",
            "4194304  15.0612 0.741536 20.3108\n",
            "N is 8388608\n",
            "8388608  30.2629 1.4409 21.0028\n",
            "N is 16777216\n",
            "16777216  61.779 2.83926 21.7588\n",
            "N is 33554432\n",
            "33554432  119.886 5.63501 21.2751\n",
            "N is 67108864\n",
            "67108864  237.075 11.222 21.1258\n",
            "N is 134217728\n",
            "134217728  483.701 22.4185 21.5759\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}